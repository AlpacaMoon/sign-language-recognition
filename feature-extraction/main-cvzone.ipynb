{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Libraries / Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone.FaceDetectionModule import FaceDetector\n",
    "from cvzone.PoseModule import PoseDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Hand, Face and Pose Detection + Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten2dList(arr, dataType=int):\n",
    "    return np.fromiter(chain.from_iterable(arr), dataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAbsLargestVal(arr):\n",
    "    return max(np.max(arr), abs(np.min(arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_landmarks(landmark_list):\n",
    "    if not landmark_list:\n",
    "        return []\n",
    "    \n",
    "    # Offset every point with respect to the first point\n",
    "    new_landmark_list = []\n",
    "    origin_x = landmark_list[0][0] \n",
    "    origin_y = landmark_list[0][1]\n",
    "    origin_z = landmark_list[0][2]\n",
    "    for each in landmark_list:\n",
    "        updated_point = [\n",
    "            each[0] - origin_x, \n",
    "            each[1] - origin_y, \n",
    "            each[2] - origin_z\n",
    "        ]\n",
    "        new_landmark_list.append(updated_point)\n",
    "    \n",
    "    # Convert to 1D-array\n",
    "    new_landmark_list = flatten2dList(new_landmark_list)\n",
    "    \n",
    "    # Get highest absolute value\n",
    "    largest_value = getAbsLargestVal(new_landmark_list)\n",
    "    \n",
    "    # Normalization\n",
    "    return new_landmark_list / largest_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_bbox(bbox, frameSize):\n",
    "    bbox = np.array(bbox, dtype=float)\n",
    "    # Convert 3rd and 4th element into coordinates instead of width/height\n",
    "    bbox[2] = bbox[0] + bbox[2]\n",
    "    bbox[3] = bbox[1] + bbox[3]\n",
    "\n",
    "    # Normalize against frame size\n",
    "    bbox[0] /= frameSize[0]\n",
    "    bbox[2] /= frameSize[0]\n",
    "    bbox[1] /= frameSize[1]\n",
    "    bbox[3] /= frameSize[1]\n",
    "\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_center(center, frameSize):\n",
    "    center = np.array(center)\n",
    "    center[0] /= frameSize[0]\n",
    "    center[1] /= frameSize[1]\n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_body_part(bodyPart, frameSize):\n",
    "    bodyPart['lmList'] = preprocess_landmarks(bodyPart['lmList'])\n",
    "    bodyPart['bbox'] = preprocess_bbox(bodyPart['bbox'], frameSize)\n",
    "    bodyPart['center'] = preprocess_center(bodyPart['center'], frameSize)\n",
    "    return bodyPart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_empty_hand(type):\n",
    "    return {\n",
    "        'lmList': np.zeros(21 * 3, dtype=int), \n",
    "        'bbox': np.zeros(4, dtype=float), \n",
    "        'center': np.zeros(2, dtype=float), \n",
    "        'type': type\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_matching_face(faces, frameSize):\n",
    "    if not faces:\n",
    "        return False\n",
    "    elif len(faces) == 1:\n",
    "        return faces[0]\n",
    "    \n",
    "    def difference(a, b):\n",
    "        return (a[0] - b[0])**2 + (a[1] - b[1])**2\n",
    "    \n",
    "    frameCenter = (frameSize[0] / 2, frameSize[1] / 2)\n",
    "\n",
    "    best_score = faces[0]\n",
    "    best_center = faces[0]\n",
    "    center_diff = difference(faces[0]['center'], frameCenter)\n",
    "\n",
    "    for each in faces:\n",
    "        if difference(each['center'], frameCenter) < center_diff:\n",
    "            best_center = each\n",
    "        if each['score'][0] > best_score['score'][0]:\n",
    "            best_score = each\n",
    "    \n",
    "    if best_center['score'][0] > 0.5:\n",
    "        return best_center\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenDetectionResult(obj):\n",
    "    return np.concatenate([obj['lmList'], obj['bbox'], obj['center']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Detectors\n",
    "handDetector = HandDetector(detectionCon=0.5, maxHands=2)\n",
    "faceDetector = FaceDetector(minDetectionCon=0.5)\n",
    "poseDetector = PoseDetector(detectionCon=0.5)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Read from camera\n",
    "        success, frame = cam.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        results = {}\n",
    "        frameSize = (frame.shape[1], frame.shape[0])\n",
    "\n",
    "        # Hand Detection\n",
    "        results['hands'], frame = handDetector.findHands(frame, draw=True)\n",
    "        if not results['hands']:\n",
    "            results['hands'] = [generate_empty_hand('Left'), generate_empty_hand('Right')]\n",
    "        elif len(results['hands']) == 1:\n",
    "            if (results['hands'][0]['type'] == 'Left'):\n",
    "                results['hands'][0] = preprocess_body_part(results['hands'][0], frameSize)\n",
    "                results['hands'].append(generate_empty_hand('Right'))\n",
    "            else:\n",
    "                results['hands'][0] = preprocess_body_part(results['hands'][0], frameSize)\n",
    "                results['hands'].insert(0, generate_empty_hand('Left'))                         \n",
    "        else:\n",
    "            results['hands'][0] = preprocess_body_part(results['hands'][0], frameSize)\n",
    "            results['hands'][1] = preprocess_body_part(results['hands'][1], frameSize)\n",
    "\n",
    "        # Pose Detection\n",
    "        # * We only use the first 23 out of the total 33 landmark points \n",
    "        #   as those represent the lower half body and are irrelevant\n",
    "        frame = poseDetector.findPose(frame, draw=True)\n",
    "        results['pose'] = {}\n",
    "        results['pose']['lmList'], tempPoseBbox = poseDetector.findPosition(frame, bboxWithHands=False)\n",
    "        if results['pose']['lmList'] and tempPoseBbox:\n",
    "            results['pose']['lmList'] = results['pose']['lmList'][:23]\n",
    "            results['pose']['bbox'] = tempPoseBbox['bbox']\n",
    "            results['pose']['center'] = tempPoseBbox['center']\n",
    "            results['pose'] = preprocess_body_part(results['pose'], frameSize)\n",
    "        else:\n",
    "            results['pose']['lmList'] = np.zeros(23 * 3, dtype=int)\n",
    "            results['pose']['bbox'] = np.zeros(4, dtype=float)\n",
    "            results['pose']['center'] = np.zeros(2, dtype=float)\n",
    "            \n",
    "        # Face Detection\n",
    "        frame, results['face'] = faceDetector.findFaces(frame, draw=True)\n",
    "        if results['face']:\n",
    "            results['face'] = select_best_matching_face(results['face'], frameSize)\n",
    "            results['face']['bbox'] = preprocess_bbox(results['face']['bbox'], frameSize)\n",
    "            results['face']['center'] = preprocess_center(results['face']['center'], frameSize)\n",
    "        else:\n",
    "            results['face'] = {\n",
    "                'bbox': np.zeros(4, dtype=float), \n",
    "                'center': np.zeros(2, dtype=float)\n",
    "            }\n",
    "\n",
    "        # Convert results into 1D-array\n",
    "        detectionResults = np.concatenate([\n",
    "            flattenDetectionResult(results['hands'][0]), \n",
    "            flattenDetectionResult(results['hands'][1]), \n",
    "            flattenDetectionResult(results['pose']), \n",
    "            results['face']['bbox'], \n",
    "            results['face']['center']\n",
    "        ])\n",
    "\n",
    "        # Show frame\n",
    "        cv2.imshow(\"Sign Language Recognition Prototype\", frame)\n",
    "\n",
    "        keyPressed = cv2.waitKey(10)\n",
    "        if (keyPressed == ord('q')):\n",
    "            pass\n",
    "\n",
    "        # Pressed 'Esc'\n",
    "        if (keyPressed == 27):\n",
    "            break\n",
    "\n",
    "except Exception as e:\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    raise e\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each output is now a 219 length 1D-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        2.12121212e-01, -1.81818182e-02, -8.48484848e-02,  4.00000000e-01,\n",
       "       -1.51515152e-01, -1.21212121e-01,  4.60606061e-01, -3.51515152e-01,\n",
       "       -1.57575758e-01,  4.78787879e-01, -5.09090909e-01, -1.81818182e-01,\n",
       "        5.15151515e-01, -3.09090909e-01, -3.63636364e-02,  7.45454545e-01,\n",
       "       -4.00000000e-01, -1.09090909e-01,  8.78787879e-01, -4.54545455e-01,\n",
       "       -1.57575758e-01,  1.00000000e+00, -5.15151515e-01, -1.87878788e-01,\n",
       "        4.30303030e-01, -4.06060606e-01, -4.24242424e-02,  6.42424242e-01,\n",
       "       -5.93939394e-01, -1.33333333e-01,  7.63636364e-01, -6.96969697e-01,\n",
       "       -1.75757576e-01,  8.66666667e-01, -7.87878788e-01, -1.93939394e-01,\n",
       "        3.03030303e-01, -4.54545455e-01, -6.66666667e-02,  4.42424242e-01,\n",
       "       -5.87878788e-01, -2.12121212e-01,  3.63636364e-01, -4.36363636e-01,\n",
       "       -2.06060606e-01,  2.90909091e-01, -3.21212121e-01, -1.63636364e-01,\n",
       "        1.45454545e-01, -4.60606061e-01, -9.69696970e-02,  2.36363636e-01,\n",
       "       -5.27272727e-01, -2.18181818e-01,  1.93939394e-01, -4.00000000e-01,\n",
       "       -2.06060606e-01,  1.51515152e-01, -3.15151515e-01, -1.63636364e-01,\n",
       "        3.06250000e-01,  4.56250000e-01,  5.64062500e-01,  7.27083333e-01,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  2.29357798e-03,  4.58715596e-02, -7.11009174e-02,\n",
       "        4.58715596e-03,  6.65137615e-02, -7.33944954e-02,  6.88073394e-03,\n",
       "        8.71559633e-02, -7.33944954e-02,  9.17431193e-03, -2.29357798e-03,\n",
       "       -6.19266055e-02,  1.14678899e-02, -1.37614679e-02, -5.73394495e-02,\n",
       "        1.37614679e-02, -2.75229358e-02, -5.27522936e-02,  1.60550459e-02,\n",
       "        1.37614679e-01, -4.81651376e-02,  1.83486239e-02, -9.17431193e-03,\n",
       "       -2.29357798e-02,  2.06422018e-02,  4.81651376e-02,  5.73394495e-02,\n",
       "        2.29357798e-02, -1.60550459e-02,  5.73394495e-02,  2.52293578e-02,\n",
       "        3.83027523e-01,  2.24770642e-01,  2.75229358e-02, -1.39908257e-01,\n",
       "        2.33944954e-01,  2.98165138e-02,  5.57339450e-01,  6.53669725e-01,\n",
       "        3.21100917e-02, -4.33486239e-01,  3.96788991e-01,  3.44036697e-02,\n",
       "        5.41284404e-01,  9.12844037e-01,  3.66972477e-02, -1.97247706e-01,\n",
       "        4.35779817e-02,  3.89908257e-02,  5.66513761e-01,  1.00000000e+00,\n",
       "        4.12844037e-02, -1.39908257e-01, -7.33944954e-02,  4.35779817e-02,\n",
       "        5.22935780e-01,  9.83944954e-01,  4.58715596e-02, -1.10091743e-01,\n",
       "       -9.17431193e-02,  4.81651376e-02,  4.81651376e-01,  9.56422018e-01,\n",
       "        5.04587156e-02, -1.12385321e-01, -4.81651376e-02,  1.60937500e-01,\n",
       "        3.97916667e-01,  8.73437500e-01,  2.83541667e+00,  0.00000000e+00,\n",
       "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectionResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Preparation for Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_LABELS_PATH = os.path.join('../action-labels.csv')\n",
    "action_labels = []\n",
    "with open(ACTION_LABELS_PATH) as f:\n",
    "    csv_reader = csv.reader(f, delimiter=\"\\n\")\n",
    "    action_labels = [each[0] for each in csv_reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data paths\n",
    "KEYPOINTS_PATH = os.path.join(\"../action-recognition/keypoints_data\")\n",
    "for action in action_labels:\n",
    "    if not os.path.exists(os.path.join(KEYPOINTS_PATH, action)):\n",
    "        os.makedirs(os.path.join(KEYPOINTS_PATH, action))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detects hands, face & pose, \n",
    "# convert them into normalized landmark/keypoint coordinates in a 1D-array, \n",
    "# and also returns the frame with the landmark connections drawn onto it\n",
    "def featureExtraction(handDetector, faceDetector, poseDetector, frame):\n",
    "    results = {}\n",
    "    frameSize = (frame.shape[1], frame.shape[0])\n",
    "\n",
    "    # Hand Detection\n",
    "    results['hands'], frame = handDetector.findHands(frame, draw=True)\n",
    "    if not results['hands']:\n",
    "        results['hands'] = [generate_empty_hand('Left'), generate_empty_hand('Right')]\n",
    "    elif len(results['hands']) == 1:\n",
    "        if (results['hands'][0]['type'] == 'Left'):\n",
    "            results['hands'][0] = preprocess_body_part(results['hands'][0], frameSize)\n",
    "            results['hands'].append(generate_empty_hand('Right'))\n",
    "        else:\n",
    "            results['hands'][0] = preprocess_body_part(results['hands'][0], frameSize)\n",
    "            results['hands'].insert(0, generate_empty_hand('Left'))                         \n",
    "    else:\n",
    "        results['hands'][0] = preprocess_body_part(results['hands'][0], frameSize)\n",
    "        results['hands'][1] = preprocess_body_part(results['hands'][1], frameSize)\n",
    "\n",
    "    # Pose Detection\n",
    "    # * We only use the first 23 out of the total 33 landmark points \n",
    "    #   as those represent the lower half body and are irrelevant\n",
    "    frame = poseDetector.findPose(frame, draw=True)\n",
    "    results['pose'] = {}\n",
    "    results['pose']['lmList'], tempPoseBbox = poseDetector.findPosition(frame, bboxWithHands=False)\n",
    "    if results['pose']['lmList'] and tempPoseBbox:\n",
    "        results['pose']['lmList'] = results['pose']['lmList'][:23]\n",
    "        results['pose']['bbox'] = tempPoseBbox['bbox']\n",
    "        results['pose']['center'] = tempPoseBbox['center']\n",
    "        results['pose'] = preprocess_body_part(results['pose'], frameSize)\n",
    "    else:\n",
    "        results['pose']['lmList'] = np.zeros(23 * 3, dtype=int)\n",
    "        results['pose']['bbox'] = np.zeros(4, dtype=float)\n",
    "        results['pose']['center'] = np.zeros(2, dtype=float)\n",
    "        \n",
    "    # Face Detection\n",
    "    frame, results['face'] = faceDetector.findFaces(frame, draw=True)\n",
    "    if results['face']:\n",
    "        results['face'] = select_best_matching_face(results['face'], frameSize)\n",
    "        results['face']['bbox'] = preprocess_bbox(results['face']['bbox'], frameSize)\n",
    "        results['face']['center'] = preprocess_center(results['face']['center'], frameSize)\n",
    "    else:\n",
    "        results['face'] = {\n",
    "            'bbox': np.zeros(4, dtype=float), \n",
    "            'center': np.zeros(2, dtype=float)\n",
    "        }\n",
    "\n",
    "    # Convert results into 1D-array\n",
    "    detectionResults = np.concatenate([\n",
    "        flattenDetectionResult(results['hands'][0]), \n",
    "        flattenDetectionResult(results['hands'][1]), \n",
    "        flattenDetectionResult(results['pose']), \n",
    "        results['face']['bbox'], \n",
    "        results['face']['center']\n",
    "    ])\n",
    "\n",
    "    return detectionResults, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many video records / training data each label should have\n",
    "trainings_per_label = 50\n",
    "\n",
    "# How many frames each video record / training data should have\n",
    "frames_per_training = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0614171028137207\n",
      "2.0135440826416016\n",
      "1.9100890159606934\n",
      "1.9114608764648438\n",
      "1.8178637027740479\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Detectors\n",
    "handDetector = HandDetector(detectionCon=0.5, maxHands=2)\n",
    "faceDetector = FaceDetector(minDetectionCon=0.5)\n",
    "poseDetector = PoseDetector(detectionCon=0.5)\n",
    "\n",
    "from time import time\n",
    "startTime = time()\n",
    "\n",
    "action = action_labels[0]\n",
    "try:\n",
    "    for training in range(trainings_per_label): \n",
    "        trainingResults = []\n",
    "        for frame_num in range(frames_per_training):\n",
    "            \n",
    "            # Read from camera\n",
    "            success, frame = cam.read()\n",
    "            if not success:\n",
    "                break\n",
    "            \n",
    "            detectionResults, frame = featureExtraction(\n",
    "                handDetector, faceDetector, poseDetector, frame)\n",
    "            \n",
    "\n",
    "            # Additional GUI\n",
    "            if frame_num == 0:\n",
    "                # Count down 3 seconds on every new training\n",
    "                for i in range(3):\n",
    "                    temp_frame = np.copy(frame)\n",
    "                    cv2.putText(temp_frame, f'Training #{training + 1} for \\'{action}\\'', (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "                    cv2.putText(temp_frame, f'Next Training in {3 - i}', (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)\n",
    "                    cv2.imshow(\"Sign Language Recognition Prototype\", temp_frame)\n",
    "                    if (cv2.waitKey(1000) == 27):\n",
    "                        raise Exception(\"Finished\")\n",
    "                startTime = time()\n",
    "                \n",
    "            else:\n",
    "                cv2.putText(frame, f'Training #{training + 1} for \\'{action}\\'', (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "            \n",
    "            # Show resulting frame\n",
    "            cv2.imshow(\"Sign Language Recognition Prototype\", frame)     \n",
    "\n",
    "            # Save the results\n",
    "            trainingResults.append(detectionResults)\n",
    "\n",
    "            # Force a 10 ms interval for processing\n",
    "            keyPressed = cv2.waitKey(1)\n",
    "\n",
    "            # Stop Program when pressed 'Esc'\n",
    "            if (keyPressed == 27):\n",
    "                raise Exception(\"Finished\")\n",
    "\n",
    "        # After all frames are finished for each training:\n",
    "        # save as .npy\n",
    "        # np.save(os.path.join(KEYPOINTS_PATH, action, str(training)), np.array(trainingResults))\n",
    "        print(time() - startTime)\n",
    "\n",
    "except Exception as e:\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(e)\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 219)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(os.path.join(KEYPOINTS_PATH, action, '0.npy')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
