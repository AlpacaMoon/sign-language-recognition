{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Time Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from time import time\n",
    "from cvzone import FPS\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import traceback\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone.FaceDetectionModule import FaceDetector\n",
    "from cvzone.PoseModule import PoseDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Feature Extraction (Hand+Face+Pose Detection)\n",
    "# Flatten a 2d np array into 1d array\n",
    "def flatten2dList(arr, dataType=int):\n",
    "    return np.fromiter(chain.from_iterable(arr), dataType)\n",
    "\n",
    "# Get the largest absolute value in an np array\n",
    "def getAbsLargestVal(arr):\n",
    "    return np.max(np.abs(arr))\n",
    "\n",
    "# Offset and normalize the landmark list\n",
    "# Returns a 1d numpy array\n",
    "def preprocess_landmarks(landmark_list):    \n",
    "    landmark_list = np.array(landmark_list, dtype=float)\n",
    "    origin = landmark_list[0]\n",
    "    \n",
    "    # Offset every point with respect to the first point\n",
    "    # Convert to 1D-array\n",
    "    new_landmark_list = (landmark_list - origin).ravel()\n",
    "    \n",
    "    # Get highest absolute value\n",
    "    largest_value = getAbsLargestVal(new_landmark_list)\n",
    "    \n",
    "    # Normalization\n",
    "    if largest_value != 0:\n",
    "        return new_landmark_list / largest_value\n",
    "    return new_landmark_list\n",
    "\n",
    "# Offset and normalize a BBOX list (BBOX = Bounding Box, used in face and hand detection)\n",
    "# Returns a 1d numpy array\n",
    "def preprocess_bbox(bbox, frameSize):\n",
    "    bbox = np.array(bbox, dtype=float)\n",
    "    # Convert 3rd and 4th element into coordinates instead of width/height\n",
    "    bbox[2] = bbox[0] + bbox[2]\n",
    "    bbox[3] = bbox[1] + bbox[3]\n",
    "\n",
    "    # Normalize against frame size\n",
    "    bbox[0] /= frameSize[0]\n",
    "    bbox[1] /= frameSize[1]\n",
    "    bbox[2] /= frameSize[0]\n",
    "    bbox[3] /= frameSize[1]\n",
    "\n",
    "    return bbox\n",
    "\n",
    "# Normalize a center vertex (a list of 2 elements)\n",
    "# Returns a 1d numpy array\n",
    "def preprocess_center(center, frameSize):\n",
    "    center = np.array(center, dtype=float)\n",
    "    center[0] /= frameSize[0]\n",
    "    center[1] /= frameSize[1]\n",
    "    return center\n",
    "\n",
    "# Preprocess (Offset and normalize) the body's landmark list, bbox and center\n",
    "def preprocess_body_part(bodyPart, frameSize):\n",
    "    bodyPart['lmList'] = preprocess_landmarks(bodyPart['lmList'])\n",
    "    bodyPart['bbox'] = preprocess_bbox(bodyPart['bbox'], frameSize)\n",
    "    bodyPart['center'] = preprocess_center(bodyPart['center'], frameSize)\n",
    "    return bodyPart\n",
    "\n",
    "# Function to generate empty/placeholder data for a hand \n",
    "# Used when a hand is not detected in frame\n",
    "def generate_empty_hand(type):\n",
    "    return {\n",
    "        'lmList': np.zeros(21 * 3, dtype=int), \n",
    "        'bbox': np.zeros(4, dtype=float), \n",
    "        'center': np.zeros(2, dtype=float), \n",
    "        'type': type\n",
    "    }\n",
    "\n",
    "# Select the best matching face, aka the one with the best score (clarity)\n",
    "# and closest to the center of the screen\n",
    "# Since the Neural network will be design to only accept one face\n",
    "def select_best_matching_face(faces, frameSize):\n",
    "    if not faces or len(faces) == 0:\n",
    "        return False\n",
    "    elif len(faces) == 1:\n",
    "        return faces[0]\n",
    "    \n",
    "    def difference(a, b):\n",
    "        return ((a[0] - b[0])**2) + ((a[1] - b[1])**2)\n",
    "    \n",
    "    frameCenter = (frameSize[0] / 2, frameSize[1] / 2)\n",
    "\n",
    "    best_score = faces[0]\n",
    "    best_center = faces[0]\n",
    "    center_diff = difference(faces[0]['center'], frameCenter)\n",
    "\n",
    "    for each in faces:\n",
    "        if difference(each['center'], frameCenter) < center_diff:\n",
    "            best_center = each\n",
    "        if each['score'][0] > best_score['score'][0]:\n",
    "            best_score = each\n",
    "    \n",
    "    if best_center['score'][0] > 0.5:\n",
    "        return best_center\n",
    "    return best_score\n",
    "\n",
    "# Flatten everything\n",
    "def flattenDetectionResult(obj):\n",
    "    # return np.fromiter(chain.from_iterable([obj['lmList'], obj['bbox'], obj['center']]), float)\n",
    "    return np.concatenate([obj['lmList'], obj['bbox'], obj['center']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detects hands, face & pose, \n",
    "# convert them into normalized landmark/keypoint coordinates in a 1D-array, \n",
    "# and also returns the frame with the landmark connections drawn onto it\n",
    "\n",
    "# Improved/Parallelised version\n",
    "def featureExtractionV3(handDetector, faceDetector, poseDetector, frame, draw=True):\n",
    "    def detectHands(handDetector, frame, frameSize, draw):\n",
    "        results = None\n",
    "        # Hand Detection\n",
    "        if (draw):\n",
    "            results, frame = handDetector.findHands(frame, draw=draw)\n",
    "        else:\n",
    "            results = handDetector.findHands(frame, draw=draw)\n",
    "\n",
    "        if not results:\n",
    "            results = [generate_empty_hand('Left'), generate_empty_hand('Right')]\n",
    "        elif len(results) == 1:\n",
    "            if (results[0]['type'] == 'Left'):\n",
    "                results[0] = preprocess_body_part(results[0], frameSize)\n",
    "                results.append(generate_empty_hand('Right'))\n",
    "            else:\n",
    "                results[0] = preprocess_body_part(results[0], frameSize)\n",
    "                results.insert(0, generate_empty_hand('Left'))                         \n",
    "        else:\n",
    "            results[0] = preprocess_body_part(results[0], frameSize)\n",
    "            results[1] = preprocess_body_part(results[1], frameSize)\n",
    "        return results\n",
    "\n",
    "    # Pose Detection\n",
    "    # **We only use the first 23 out of the total 33 landmark points \n",
    "    #   as those represent the lower half body and are irrelevant to sign language interpretation\n",
    "    def detectPose(poseDetector, frame, draw):\n",
    "        frame = poseDetector.findPose(frame, draw=draw)\n",
    "        results, _ = poseDetector.findPosition(frame, bboxWithHands=False)\n",
    "        if results:\n",
    "            results = preprocess_landmarks(results[:23])\n",
    "        else:\n",
    "            results = np.zeros(23, dtype=int)\n",
    "        return results\n",
    "    \n",
    "    # Face Detection\n",
    "    def detectFace(faceDetector, frame, frameSize, draw):\n",
    "        frame, results = faceDetector.findFaces(frame, draw=draw)\n",
    "        if results:\n",
    "            results = select_best_matching_face(results, frameSize)\n",
    "            results['bbox'] = preprocess_bbox(results['bbox'], frameSize)\n",
    "            results['center'] = preprocess_center(results['center'], frameSize)\n",
    "        else:\n",
    "            results = {\n",
    "                'bbox': np.zeros(4, dtype=float), \n",
    "                'center': np.zeros(2, dtype=float)\n",
    "            }\n",
    "        return results\n",
    "\n",
    "    frameSize = (frame.shape[1], frame.shape[0])\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        t1 = executor.submit(detectHands, handDetector, frame, frameSize, draw)\n",
    "        t2 = executor.submit(detectPose, poseDetector, frame, draw)\n",
    "        t3 = executor.submit(detectFace, faceDetector, frame, frameSize, draw)\n",
    "        \n",
    "        # Convert results into 1D-array\n",
    "        detectionResults = flatten2dList([\n",
    "            flattenDetectionResult(t1.result()[0]), \n",
    "            flattenDetectionResult(t1.result()[1]), \n",
    "            t2.result(), \n",
    "            t3.result()['bbox'],\n",
    "            t3.result()['center'],\n",
    "            t3.result()['center'] - t1.result()[0]['center'],\n",
    "            t3.result()['center'] - t1.result()[1]['center']\n",
    "        ], dataType=float)\n",
    "\n",
    "        return detectionResults, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " 'airplane']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Load the model from the H5 file\n",
    "model = tf.keras.models.load_model('../static-recognition/models/static_model.h5')\n",
    "\n",
    "from static_files_io import readActionLabels\n",
    "\n",
    "static_labels = readActionLabels()\n",
    "static_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "# Detectors\n",
    "handDetector = HandDetector(detectionCon=0.5, maxHands=2)\n",
    "faceDetector = FaceDetector(minDetectionCon=0.5)\n",
    "poseDetector = PoseDetector(detectionCon=0.5)\n",
    "\n",
    "fpsReader = FPS()\n",
    "\n",
    "timeStats = []\n",
    "\n",
    "try:\n",
    "    predictionHistory = deque()\n",
    "    detectionThreshold = 0.999    \n",
    "    predictionCooldown = 1.0\n",
    "    # the first time append should eliminate predictionCooldown\n",
    "    lastAppendTime = time() + predictionCooldown\n",
    "\n",
    "    while True:\n",
    "        startTime = time()\n",
    "\n",
    "        # Read from camera\n",
    "        success, frame = cam.read()\n",
    "        if not success:\n",
    "            raise Exception(\"No Frames Read\")\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Pose Detection\n",
    "        detectionResults, frame = featureExtractionV3(\n",
    "            handDetector, faceDetector, poseDetector, frame)\n",
    "\n",
    "        detectionResults = np.expand_dims(\n",
    "            detectionResults, axis=0) # reshape detection result\n",
    "\n",
    "        predictionResults = model.predict(\n",
    "            x=detectionResults,\n",
    "            verbose=0,\n",
    "            use_multiprocessing=True,\n",
    "            workers=4\n",
    "        )[0]\n",
    "        \n",
    "        # Get predicted character and accuracy\n",
    "        predCharacter = static_labels[np.argmax(predictionResults)]\n",
    "        predAccuracy = predictionResults[np.argmax(predictionResults)]\n",
    "        \n",
    "        cv2.putText(frame, (predCharacter + \":\"+ str(predAccuracy)), (15, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)\n",
    "        \n",
    "        if predAccuracy >= detectionThreshold:            \n",
    "            # If predictionHistory is not empty\n",
    "            # If predCharacter is the same as the last appended character\n",
    "            # Check if 0.5 seconds have passed since the last append\n",
    "            if predictionHistory and predCharacter == predictionHistory[-1] and time() <= lastAppendTime + predictionCooldown:\n",
    "                # Do nothing, don't append\n",
    "                pass\n",
    "            else:\n",
    "                predictionHistory.append(predCharacter)\n",
    "                # Reset the timestamp when a new character is detected\n",
    "                lastAppendTime = time()\n",
    "\n",
    "            if len(predictionHistory) > 5:\n",
    "                    predictionHistory.popleft()  \n",
    "                           \n",
    "                        \n",
    "        cv2.putText(frame, str(predictionHistory), (15, 120),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)\n",
    "        \n",
    "\n",
    "        fps, frame = fpsReader.update(frame, pos=(\n",
    "            950, 80), color=(0, 255, 0), scale=5, thickness=5)\n",
    "\n",
    "        # Show resulting frame\n",
    "        # cv2.putText(frame, f'Training #{training + 1} for \\'{action}\\'', (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "        cv2.imshow(\"Sign Language Recognition Prototype\", frame)\n",
    "\n",
    "        timeStats.append(time() - startTime)\n",
    "\n",
    "        keyPressed = cv2.waitKey(1)\n",
    "        # Stop Program when pressed 'Esc'\n",
    "        if keyPressed == 27:\n",
    "            raise Exception(\"Finished\")\n",
    "        elif keyPressed == ord('c'):\n",
    "            predictionHistory.clear()\n",
    "            lastAppendTime = time() + predictionCooldown\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(e)\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "# Detectors\n",
    "handDetector = HandDetector(detectionCon=0.5, maxHands=2)\n",
    "faceDetector = FaceDetector(minDetectionCon=0.5)\n",
    "poseDetector = PoseDetector(detectionCon=0.5)\n",
    "\n",
    "fpsReader = FPS()\n",
    "\n",
    "timeStats = []\n",
    "\n",
    "try:\n",
    "    keypointsHistory = deque()\n",
    "    predictionHistory = deque()\n",
    "    detectionThreshold = 0.999\n",
    "\n",
    "    lastPredictionTime = time()\n",
    "    lastAppendTime = time()\n",
    "    predictionCooldown = 0.7\n",
    "\n",
    "    while True:\n",
    "        startTime = time()\n",
    "\n",
    "        # Read from camera\n",
    "        success, frame = cam.read()\n",
    "        if not success:\n",
    "            raise Exception(\"No Frames Read\")\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Pose Detection\n",
    "        detectionResults, frame = featureExtractionV3(\n",
    "            handDetector, faceDetector, poseDetector, frame)\n",
    "\n",
    "        detectionResults = np.expand_dims(\n",
    "            detectionResults, axis=0)  # Reshape to (1, 138, 3)\n",
    "\n",
    "        # Semantic Prediction\n",
    "        keypointsHistory.append(detectionResults)\n",
    "        \n",
    "        if time() > lastPredictionTime + predictionCooldown:\n",
    "            predictionResults = model.predict(\n",
    "                x=detectionResults,\n",
    "                verbose=0,\n",
    "                use_multiprocessing=True,\n",
    "                workers=4\n",
    "            )[0]\n",
    "\n",
    "            predCharacter = static_labels[np.argmax(predictionResults)]\n",
    "            predAccuracy = predictionResults[np.argmax(predictionResults)]\n",
    "            \n",
    "            cv2.putText(frame, (predCharacter + \":\"+ str(predAccuracy)), (15, 70),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)\n",
    "            \n",
    "            if predAccuracy >= detectionThreshold:                \n",
    "                # If predictionHistory is not empty\n",
    "                # If predCharacter is the same as the last appended character\n",
    "                if predictionHistory and predCharacter == predictionHistory[-1]:\n",
    "                    # Check if 0.5 seconds have passed since the last append\n",
    "                    if time() > lastAppendTime + predictionCooldown:\n",
    "                        predictionHistory.append(predCharacter)\n",
    "                        # Reset the timestamp when a new character is detected\n",
    "                        lastAppendTime = time()\n",
    "                else:\n",
    "                    # do not need to check append time, directly append\n",
    "                    predictionHistory.append(predCharacter)\n",
    "                    # Reset the timestamp when a new character is detected\n",
    "                    lastAppendTime = time()\n",
    "                    \n",
    "                if len(predictionHistory) > 5:\n",
    "                        predictionHistory.popleft()      \n",
    "                        \n",
    "        cv2.putText(frame, str(predictionHistory), (15, 120),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)\n",
    "        \n",
    "\n",
    "        fps, frame = fpsReader.update(frame, pos=(\n",
    "            950, 80), color=(0, 255, 0), scale=5, thickness=5)\n",
    "\n",
    "        # Show resulting frame\n",
    "        # cv2.putText(frame, f'Training #{training + 1} for \\'{action}\\'', (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "        cv2.imshow(\"Sign Language Recognition Prototype\", frame)\n",
    "\n",
    "        timeStats.append(time() - startTime)\n",
    "\n",
    "        keyPressed = cv2.waitKey(1)\n",
    "        # Stop Program when pressed 'Esc'\n",
    "        if keyPressed == 27:\n",
    "            raise Exception(\"Finished\")\n",
    "        elif keyPressed == ord('c'):\n",
    "            predictionHistory.clear()\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(e)\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10175919532775879,\n",
       " 0.10361623764038086,\n",
       " 0.10113692283630371,\n",
       " 0.1145467758178711,\n",
       " 0.10755228996276855,\n",
       " 0.12157011032104492,\n",
       " 0.1219327449798584,\n",
       " 0.10681796073913574,\n",
       " 0.10911417007446289,\n",
       " 0.11156964302062988,\n",
       " 0.11264228820800781,\n",
       " 0.11280012130737305,\n",
       " 0.10521650314331055,\n",
       " 0.10647320747375488,\n",
       " 0.10957932472229004,\n",
       " 0.10908794403076172,\n",
       " 0.11562299728393555,\n",
       " 0.10816383361816406,\n",
       " 0.11586999893188477,\n",
       " 0.11254763603210449,\n",
       " 0.1248617172241211,\n",
       " 0.1052253246307373,\n",
       " 0.11150956153869629,\n",
       " 0.10675334930419922,\n",
       " 0.1177983283996582,\n",
       " 0.10676050186157227,\n",
       " 0.1095120906829834,\n",
       " 0.11430859565734863,\n",
       " 0.10734868049621582,\n",
       " 0.10875391960144043,\n",
       " 0.1045522689819336,\n",
       " 0.10727524757385254,\n",
       " 0.11341452598571777,\n",
       " 0.12044215202331543,\n",
       " 0.10878610610961914,\n",
       " 0.11257386207580566,\n",
       " 0.1128075122833252,\n",
       " 0.11462211608886719,\n",
       " 0.11231565475463867,\n",
       " 0.11007547378540039,\n",
       " 0.10777020454406738,\n",
       " 0.11254668235778809,\n",
       " 0.10651445388793945,\n",
       " 0.11215090751647949,\n",
       " 0.10658669471740723,\n",
       " 0.10856389999389648,\n",
       " 0.11106085777282715,\n",
       " 0.12116146087646484,\n",
       " 0.10828781127929688,\n",
       " 0.11085677146911621,\n",
       " 0.10677289962768555,\n",
       " 0.11258530616760254,\n",
       " 0.10759782791137695,\n",
       " 0.10959315299987793,\n",
       " 0.10755586624145508,\n",
       " 0.10802268981933594,\n",
       " 0.10755348205566406,\n",
       " 0.10861611366271973,\n",
       " 0.1085665225982666,\n",
       " 0.10961318016052246,\n",
       " 0.11012911796569824,\n",
       " 0.10783100128173828,\n",
       " 0.10801506042480469,\n",
       " 0.11058735847473145,\n",
       " 0.11008787155151367,\n",
       " 0.10760068893432617,\n",
       " 0.106903076171875,\n",
       " 0.11432313919067383,\n",
       " 0.12048053741455078,\n",
       " 0.10985398292541504,\n",
       " 0.10753011703491211,\n",
       " 0.1056821346282959,\n",
       " 0.10881781578063965,\n",
       " 0.11942338943481445,\n",
       " 0.11080408096313477,\n",
       " 0.11359524726867676,\n",
       " 0.11259984970092773,\n",
       " 0.12143468856811523,\n",
       " 0.10684442520141602,\n",
       " 0.10724091529846191,\n",
       " 0.12013435363769531,\n",
       " 0.10833621025085449,\n",
       " 0.1078193187713623,\n",
       " 0.11338496208190918,\n",
       " 0.11889362335205078,\n",
       " 0.10780477523803711,\n",
       " 0.11453104019165039,\n",
       " 0.10928535461425781,\n",
       " 0.10761547088623047,\n",
       " 0.10556840896606445,\n",
       " 0.1075897216796875,\n",
       " 0.12668299674987793,\n",
       " 0.10384869575500488,\n",
       " 0.1197197437286377,\n",
       " 0.1158590316772461,\n",
       " 0.1195681095123291,\n",
       " 0.11055326461791992,\n",
       " 0.11053109169006348,\n",
       " 0.10474777221679688,\n",
       " 0.12638115882873535,\n",
       " 0.10778498649597168,\n",
       " 0.10939526557922363,\n",
       " 0.11089158058166504,\n",
       " 0.10655450820922852,\n",
       " 0.10757827758789062,\n",
       " 0.10556268692016602,\n",
       " 0.10858964920043945,\n",
       " 0.10953760147094727,\n",
       " 0.12024164199829102,\n",
       " 0.11175894737243652,\n",
       " 0.12530016899108887,\n",
       " 0.10918235778808594,\n",
       " 0.1110692024230957,\n",
       " 0.09951066970825195,\n",
       " 0.12187576293945312,\n",
       " 0.12874650955200195,\n",
       " 0.11830735206604004,\n",
       " 0.12469649314880371,\n",
       " 0.11506009101867676,\n",
       " 0.12998390197753906,\n",
       " 0.11008191108703613,\n",
       " 0.10237503051757812,\n",
       " 0.10035443305969238,\n",
       " 0.10840654373168945,\n",
       " 0.09885168075561523,\n",
       " 0.1009681224822998,\n",
       " 0.09881973266601562]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeStats[10:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
