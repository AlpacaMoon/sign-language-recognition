{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "rawFrame = np.load(os.path.join(\"sample_data\", \"rawFrame.npy\"))\n",
    "dr = np.load(os.path.join(\"sample_data\", \"rawFrame_dr.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawFrame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "blankFrame = np.zeros((720, 1280, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left Hand\n",
    "21*3 + 4 + 2 = 69\n",
    "[0:68]\n",
    "\n",
    "Right Hand\n",
    "21*3 + 4 + 2 = 69\n",
    "[69:137]\n",
    "\n",
    "Pose\n",
    "23*4 = 92\n",
    "[138:229]\n",
    "\n",
    "Face\n",
    "4 + 2 = 6\n",
    "[230:235]\n",
    "\n",
    "Diff_Lefthand_face\n",
    "2\n",
    "[236:237]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cx(n):\n",
    "    return int(dr[n] * 1280)\n",
    "\n",
    "def cy(n):\n",
    "    return int(dr[n] * 720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left hand\n",
    "lh_lmlist = []\n",
    "for i in range(21):\n",
    "    temp = (int(dr[i * 3 + 0] * 1280), int(dr[i * 3 + 1] * 720))\n",
    "    lh_lmlist.append(temp)\n",
    "\n",
    "lh_center = (cx(67), cy(68))\n",
    "lh_bbox = ((cx(63), cy(64)), (cx(65), cy(66)))\n",
    "\n",
    "displace = 69\n",
    "# Right hand\n",
    "rh_lmlist = []\n",
    "for i in range(21):\n",
    "    temp = (cx(i * 3 + 0 + displace), cy(i * 3 + 1+displace))\n",
    "    rh_lmlist.append(temp)\n",
    "\n",
    "rh_center = (cx(67+displace), cy(68+displace))\n",
    "rh_bbox = ((cx(63+displace), cy(64+displace)), (cx(65+displace), cy(66+displace)))\n",
    "\n",
    "# Pose\n",
    "displace = 69 + 69\n",
    "pose_lmlist = []\n",
    "for i in range(23):\n",
    "    temp = (cx(i * 4 + 0 + displace), cy(i * 4 + 1+displace))\n",
    "    pose_lmlist.append(temp)\n",
    "\n",
    "# Face\n",
    "displace = 69+69+92\n",
    "face_bbox = ((cx(displace+0), cy(displace+1)), (cx(displace+2), cy(displace+3)))\n",
    "face_center = (cx(displace + 4), cy(displace+5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "newFrame = np.copy(blankFrame)\n",
    "# for point in lh_lmlist:\n",
    "#     cv2.circle(newFrame, (point[0], point[1]), 2, (0, 0, 255), 2)\n",
    "# cv2.rectangle(newFrame, lh_bbox[0], lh_bbox[1], (0, 255, 0), 1)\n",
    "# cv2.circle(newFrame, lh_center, 2, (255, 255, 0), 3)\n",
    "\n",
    "# for point in rh_lmlist:\n",
    "#     cv2.circle(newFrame, (point[0], point[1]), 2, (0, 0, 255), 2)\n",
    "# cv2.rectangle(newFrame, rh_bbox[0], rh_bbox[1], (0, 255, 0), 1)\n",
    "# cv2.circle(newFrame, rh_center, 2, (255, 255, 0), 3)\n",
    "\n",
    "\n",
    "for point in pose_lmlist:\n",
    "    cv2.circle(newFrame, (point[0], point[1]), 2, (0, 255, 255), 2)\n",
    "\n",
    "# Face\n",
    "cv2.rectangle(newFrame, face_bbox[0], face_bbox[1], (0, 255, 0), 1)\n",
    "cv2.circle(newFrame, face_center, 2, (255, 255, 0), 3)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_x(detectionResult):\n",
    "    output = np.copy(detectionResult)\n",
    "\n",
    "    # Left Hand\n",
    "    displace = 0\n",
    "    for i in range(21):\n",
    "        output[i * 3 + 0 + displace] = 1 - output[i * 3 + 0 + displace]\n",
    "    output[63 + displace] = 1 - output[63 + displace]\n",
    "    output[65 + displace] = 1 - output[65 + displace]\n",
    "    output[67 + displace] = 1 - output[67 + displace]\n",
    "\n",
    "    # Right Hand\n",
    "    displace = 69\n",
    "    for i in range(21):\n",
    "        output[i * 3 + 0 + displace] = 1 - output[i * 3 + 0 + displace]\n",
    "    output[63 + displace] = 1 - output[63 + displace]\n",
    "    output[65 + displace] = 1 - output[65 + displace]\n",
    "    output[67 + displace] = 1 - output[67 + displace]\n",
    "\n",
    "    # Pose\n",
    "    displace = 69 + 69\n",
    "    for i in range(23):\n",
    "        output[i * 4 + displace + 0] = 1 - output[i * 4 + displace + 0]\n",
    "    \n",
    "    # Face\n",
    "    displace = 69 + 69 + 92\n",
    "    # bbox\n",
    "    output[displace + 0] = 1 - output[displace + 0]\n",
    "    output[displace + 2] = 1 - output[displace + 2]\n",
    "    # center\n",
    "    output[displace + 4] = 1 - output[displace + 4]\n",
    "\n",
    "    # distance\n",
    "    displace2 = 69 + 69 + 92 + 6\n",
    "    output[displace2 + 0] = output[displace + 4] - output[0 + 67]\n",
    "    output[displace2 + 2] = output[displace + 4] - output[69 + 67]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_lh_lmlist = [(1280 - i[0], i[1]) for i in lh_lmlist]\n",
    "for point in flipped_lh_lmlist:\n",
    "    cv2.circle(newFrame, (point[0], point[1]), 2, (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    \n",
    "    while True:\n",
    "        cv2.imshow(\"dsa\", newFrame)\n",
    "\n",
    "        if cv2.waitKey(10) == 27:\n",
    "            raise Exception('Finished')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 720, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newFrame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5404\\2127446182.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcvzone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHandTrackingModule\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHandDetector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcvzone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFaceDetectionModule\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFaceDetector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcvzone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPoseModule\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPoseDetector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfutures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TARUMT\\anaconda3\\lib\\site-packages\\cvzone\\HandTrackingModule.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TARUMT\\anaconda3\\lib\\site-packages\\mediapipe\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtasks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TARUMT\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solutions\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;34m\"\"\"MediaPipe Solutions Python API.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawing_styles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawing_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_detection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TARUMT\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solutions\\drawing_styles.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mface_mesh_connections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhands_connections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawing_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDrawingSpec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhands\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHandLandmark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPoseLandmark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TARUMT\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solutions\\drawing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TARUMT\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;31m# cbook must import matplotlib only within function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMatplotlibDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msanitize_sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmplDeprecation\u001b[0m  \u001b[1;31m# deprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TARUMT\\anaconda3\\lib\\site-packages\\matplotlib\\rcsetup.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mls_mapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColormap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_color_like\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfontconfig_pattern\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparse_fontconfig_pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enums\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mJoinStyle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCapStyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TARUMT\\anaconda3\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumbers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNumber\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPngInfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone.FaceDetectionModule import FaceDetector\n",
    "from cvzone.PoseModule import PoseDetector\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from itertools import chain\n",
    "\n",
    "class FeatureExtractionModule():\n",
    "    def __init__(self, **kwargs):\n",
    "        # Detectors\n",
    "        self.handDetector = HandDetector(detectionCon=0.5, maxHands=2)\n",
    "        self.faceDetector = FaceDetector(minDetectionCon=0.5)\n",
    "        self.poseDetector = PoseDetector(detectionCon=0.5)\n",
    "\n",
    "    def detectHands(self, handDetector, frame, frameSize, draw):\n",
    "        results = [0, 0]\n",
    "        tempResults = []\n",
    "        # Hand Detection\n",
    "        if draw:\n",
    "            tempResults, frame = handDetector.findHands(frame, draw=draw, flipType=False)\n",
    "        else:\n",
    "            tempResults = handDetector.findHands(frame, draw=draw, flipType=False)\n",
    "\n",
    "        if not tempResults:\n",
    "            results = [self.generate_empty_hand(\"Left\"), self.generate_empty_hand(\"Right\")]\n",
    "        elif len(tempResults) == 1:\n",
    "            if tempResults[0][\"type\"] == \"Left\":\n",
    "                results = [self.preprocess_body_part(tempResults[0], frameSize), self.generate_empty_hand(\"Right\")]\n",
    "            else:\n",
    "                results = [self.generate_empty_hand(\"Left\"), self.preprocess_body_part(tempResults[0], frameSize)]\n",
    "        else:\n",
    "            if tempResults[0]['type'] == 'Right' and tempResults[1]['type'] == 'Left':\n",
    "                results[0] = tempResults[1]\n",
    "                results[1] = tempResults[0]\n",
    "            elif tempResults[0]['type'] == 'Left' and tempResults[1]['type'] == 'Right':\n",
    "                results[0] = tempResults[0]\n",
    "                results[1] = tempResults[1]\n",
    "\n",
    "            # If both detected hands are both left or both right\n",
    "            elif tempResults[0]['center'][0] > tempResults[1]['center'][0]:\n",
    "                results[0] = tempResults[1]\n",
    "                results[1] = tempResults[0]\n",
    "            else:\n",
    "                results[0] = tempResults[0]\n",
    "                results[1] = tempResults[1]\n",
    "\n",
    "            results[0] = self.preprocess_body_part(results[0], frameSize)\n",
    "            results[1] = self.preprocess_body_part(results[1], frameSize)\n",
    "\n",
    "        return results\n",
    "\n",
    "    # Pose Detection\n",
    "    # **We only use the first 23 out of the total 33 landmark points\n",
    "    #   as those represent the lower half body and are irrelevant to sign language interpretation\n",
    "    def detectPose(self, poseDetector, frame, frameSize, draw):\n",
    "        frame = poseDetector.findPose(frame, draw=draw)\n",
    "        if poseDetector.results.pose_landmarks:\n",
    "            results = np.array([[i.x, i.y, i.z, i.visibility] for i in poseDetector.results.pose_landmarks.landmark[:23]])\n",
    "            return results.ravel()\n",
    "\n",
    "        # frame = poseDetector.findPose(frame, draw=draw)\n",
    "        # results, _ = poseDetector.findPosition(frame, bboxWithHands=False)\n",
    "        # print('---------------')\n",
    "        # print('e1', np.array(results)[:, -1])\n",
    "        # if results:\n",
    "        #     return np.array(results).flatten()\n",
    "        #     # return self.preprocess_landmarks(results[:23], frameSize)\n",
    "        # print('e2', results)\n",
    "        return np.zeros(69, dtype=float)\n",
    "        \n",
    "\n",
    "    # Face Detection\n",
    "    def detectFace(self, faceDetector, frame, frameSize, draw):\n",
    "        frame, results = faceDetector.findFaces(frame, draw=draw)\n",
    "        if results:\n",
    "            results = self.select_best_matching_face(results, frameSize)\n",
    "            results[\"bbox\"] = self.preprocess_bbox(results[\"bbox\"], frameSize)\n",
    "            results[\"center\"] = self.preprocess_center(results[\"center\"], frameSize)\n",
    "            return results\n",
    "\n",
    "        return {\n",
    "            \"bbox\": np.zeros(4, dtype=float),\n",
    "            \"center\": np.zeros(2, dtype=float),\n",
    "        }\n",
    "\n",
    "    # Detects hands, face & pose,\n",
    "    # convert them into normalized landmark/keypoint coordinates in a 1D-array,\n",
    "    # and also returns the frame with the landmark connections drawn onto it\n",
    "    def parallelFeatureExtraction(\n",
    "        self, handDetector, faceDetector, poseDetector, frame, draw=True\n",
    "    ):\n",
    "        frameSize = (frame.shape[1], frame.shape[0])\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            t1 = executor.submit(self.detectHands, handDetector, frame, frameSize, draw)\n",
    "            t2 = executor.submit(self.detectPose, poseDetector, frame, frameSize, draw)\n",
    "            t3 = executor.submit(self.detectFace, faceDetector, frame, frameSize, draw)\n",
    "\n",
    "            # Convert results into 1D-array\n",
    "            detectionResults = self.flatten2dList(\n",
    "                [\n",
    "                    self.flattenDetectionResult(t1.result()[0]),\n",
    "                    self.flattenDetectionResult(t1.result()[1]),\n",
    "                    t2.result(),\n",
    "                    t3.result()[\"bbox\"],\n",
    "                    t3.result()[\"center\"],\n",
    "                    t3.result()[\"center\"] - t1.result()[0][\"center\"],\n",
    "                    t3.result()[\"center\"] - t1.result()[1][\"center\"],\n",
    "                ],\n",
    "                dataType=float,\n",
    "            )\n",
    "\n",
    "            return detectionResults, frame\n",
    "\n",
    "    # Offset and normalize the landmark list\n",
    "    # Returns a 1d numpy array\n",
    "    def preprocess_landmarks(self, landmark_list, frameSize):\n",
    "        np_landmark_list = np.array(landmark_list, dtype=float)\n",
    "        np_frameSize = np.array([frameSize[0], frameSize[1], frameSize[0]])\n",
    "        return (np_landmark_list / np_frameSize).ravel()\n",
    "\n",
    "\n",
    "    # Offset and normalize a BBOX list (BBOX = Bounding Box, used in face and hand detection)\n",
    "    # Returns a 1d numpy array\n",
    "    def preprocess_bbox(self, bbox, frameSize):\n",
    "        bbox = np.array(bbox, dtype=float)\n",
    "        # Convert 3rd and 4th element into coordinates instead of width/height\n",
    "        bbox[2] = bbox[0] + bbox[2]\n",
    "        bbox[3] = bbox[1] + bbox[3]\n",
    "\n",
    "        # Normalize against frame size\n",
    "        bbox[0] /= frameSize[0]\n",
    "        bbox[1] /= frameSize[1]\n",
    "        bbox[2] /= frameSize[0]\n",
    "        bbox[3] /= frameSize[1]\n",
    "\n",
    "        return bbox\n",
    "\n",
    "\n",
    "    # Normalize a center vertex (a list of 2 elements)\n",
    "    # Returns a 1d numpy array\n",
    "    def preprocess_center(self, center, frameSize):\n",
    "        center = np.array(center, dtype=float)\n",
    "        center[0] /= frameSize[0]\n",
    "        center[1] /= frameSize[1]\n",
    "        return center\n",
    "\n",
    "\n",
    "    # Preprocess (Offset and normalize) the body's landmark list, bbox and center\n",
    "    def preprocess_body_part(self, bodyPart, frameSize):\n",
    "        bodyPart[\"lmList\"] = self.preprocess_landmarks(bodyPart[\"lmList\"], frameSize)\n",
    "        bodyPart[\"bbox\"] = self.preprocess_bbox(bodyPart[\"bbox\"], frameSize)\n",
    "        bodyPart[\"center\"] = self.preprocess_center(bodyPart[\"center\"], frameSize)\n",
    "        return bodyPart\n",
    "\n",
    "\n",
    "    # Function to generate empty/placeholder data for a hand\n",
    "    # Used when a hand is not detected in frame\n",
    "    def generate_empty_hand(self, type):\n",
    "        return {\n",
    "            \"lmList\": np.zeros(63, dtype=float),\n",
    "            \"bbox\": np.zeros(4, dtype=float),\n",
    "            \"center\": np.zeros(2, dtype=float),\n",
    "            \"type\": type,\n",
    "        }\n",
    "\n",
    "\n",
    "    # Select the best matching face, aka the one with the best score (clarity)\n",
    "    # and closest to the center of the screen\n",
    "    # Since the Neural network will be design to only accept one face\n",
    "    def select_best_matching_face(self, faces, frameSize):\n",
    "        if not faces or len(faces) == 0:\n",
    "            return False\n",
    "        elif len(faces) == 1:\n",
    "            return faces[0]\n",
    "\n",
    "        def difference(a, b):\n",
    "            return ((a[0] - b[0]) ** 2) + ((a[1] - b[1]) ** 2)\n",
    "\n",
    "        frameCenter = (frameSize[0] / 2, frameSize[1] / 2)\n",
    "\n",
    "        best_score = faces[0]\n",
    "        best_center = faces[0]\n",
    "        center_diff = difference(faces[0][\"center\"], frameCenter)\n",
    "\n",
    "        for each in faces[1:]:\n",
    "            if difference(each[\"center\"], frameCenter) < center_diff:\n",
    "                best_center = each\n",
    "            if each[\"score\"][0] > best_score[\"score\"][0]:\n",
    "                best_score = each\n",
    "\n",
    "        if best_center[\"score\"][0] > 0.5:\n",
    "            return best_center\n",
    "        return best_score\n",
    "\n",
    "    # Flatten a 2d np array into 1d array\n",
    "    def flatten2dList(self, arr, dataType=float):\n",
    "        return np.fromiter(chain.from_iterable(arr), dataType)\n",
    "\n",
    "    # Flatten everything\n",
    "    def flattenDetectionResult(self, obj):\n",
    "        return np.concatenate([obj[\"lmList\"], obj[\"bbox\"], obj[\"center\"]])\n",
    "\n",
    "\n",
    "    def extractFeatures(self, frame):\n",
    "        detectionResults, frame = self.parallelFeatureExtraction(\n",
    "            self.handDetector, self.faceDetector, self.poseDetector, frame\n",
    "        )\n",
    "\n",
    "        return detectionResults, frame\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if Flip_x works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HandDetector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5404\\3536807803.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFeatureExtractionModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrawFrameCopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mr1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawFrameCopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5404\\166648962.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;31m# Detectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandDetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHandDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetectionCon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxHands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfaceDetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFaceDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminDetectionCon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposeDetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPoseDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetectionCon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'HandDetector' is not defined"
     ]
    }
   ],
   "source": [
    "fem = FeatureExtractionModule()\n",
    "rawFrameCopy = np.copy(rawFrame)\n",
    "r1 = fem.extractFeatures(rawFrameCopy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.equal(r1, dr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.flip(rawFrameCopy, 1)\n",
    "r2 = fem.extractFeatures(rawFrameCopy)\n",
    "print(np.equal(r2, dr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
